{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "artistic-vermont",
   "metadata": {},
   "source": [
    "# Hybrid ML with AzureClusterlessHPC\n",
    "\n",
    "In this example we show how we can leverage AzureClusterlessHCP for hybrid machine learning. Users can run this Jupyter notebook on their laptop or a CPU machine in the cloud to develop and test their model. Once you're ready for training, you can simply remotely execute the training function on one or multiple GPU instances and fetch the trained network upon completion. There is no need for manually spinning up a GPU instance and for rerunning the full notebook.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, we set the required environment variables, load the package and then create an (empty) pool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "trained-feature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created pool 1 of 1 in southcentralus with 3 nodes.\n"
     ]
    }
   ],
   "source": [
    "# Set environment variable to parameter file\n",
    "ENV[\"PARAMETERS\"] = joinpath(pwd(), \"parameters.json\")\n",
    "\n",
    "# Load package\n",
    "using AzureClusterlessHPC, PyPlot\n",
    "batch_clear()\n",
    "\n",
    "# Create pool of GPUs\n",
    "create_pool();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-omaha",
   "metadata": {},
   "source": [
    "## VGG-16 example for CIFAR10\n",
    "\n",
    "The remainder of this notebook was taken from Flux' model zoo and contains the VGG16 model to train the CIFAR10 dataset. You can find the original example [here](https://github.com/FluxML/model-zoo/blob/master/vision/vgg_cifar10/vgg_cifar10.jl) (MIT expat license).\n",
    "\n",
    "The only modifications with respect to the original code are the additions of the `@batchexec` macro for all function definitions and package loading statements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "preliminary-interview",
   "metadata": {},
   "outputs": [],
   "source": [
    "@batchdef begin\n",
    "    using Flux\n",
    "    using Flux: onehotbatch, onecold, flatten\n",
    "    using Flux.Losses: logitcrossentropy\n",
    "    using Flux.Data: DataLoader\n",
    "    using Parameters: @with_kw\n",
    "    using Statistics: mean\n",
    "    using CUDA\n",
    "    using MLDatasets: CIFAR10\n",
    "    using MLDataPattern: splitobs\n",
    "    ENV[\"DATADEPS_ALWAYS_ACCEPT\"] = \"true\"\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-wound",
   "metadata": {},
   "source": [
    "Next, we define the data loader function for the training data, which downloads the CIFAR10 dataset if it is not available locally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "assisted-determination",
   "metadata": {},
   "outputs": [],
   "source": [
    "@batchdef function get_processed_data(args)\n",
    "    x, y = CIFAR10.traindata()\n",
    "\n",
    "    (train_x, train_y), (val_x, val_y) = splitobs((x, y), at=1-args.valsplit)\n",
    "\n",
    "    train_x = float(train_x)\n",
    "    train_y = onehotbatch(train_y, 0:9)\n",
    "    val_x = float(val_x)\n",
    "    val_y = onehotbatch(val_y, 0:9)\n",
    "    \n",
    "    return (train_x, train_y), (val_x, val_y)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-easter",
   "metadata": {},
   "source": [
    "Similarily, we supply an equivalent function for the testing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "informative-mixer",
   "metadata": {},
   "outputs": [],
   "source": [
    "@batchdef function get_test_data()\n",
    "    test_x, test_y = CIFAR10.testdata()\n",
    "   \n",
    "    test_x = float(test_x)\n",
    "    test_y = onehotbatch(test_y, 0:9)\n",
    "    \n",
    "    return test_x, test_y\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recovered-metabolism",
   "metadata": {},
   "source": [
    "Next, we implement a function that creates an instance of the VGG16 model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "specific-island",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG16 and VGG19 models\n",
    "@batchdef function vgg16()\n",
    "    Chain(\n",
    "        Conv((3, 3), 3 => 64, relu, pad=(1, 1), stride=(1, 1)),\n",
    "        BatchNorm(64),\n",
    "        Conv((3, 3), 64 => 64, relu, pad=(1, 1), stride=(1, 1)),\n",
    "        BatchNorm(64),\n",
    "        MaxPool((2,2)),\n",
    "        Conv((3, 3), 64 => 128, relu, pad=(1, 1), stride=(1, 1)),\n",
    "        BatchNorm(128),\n",
    "        Conv((3, 3), 128 => 128, relu, pad=(1, 1), stride=(1, 1)),\n",
    "        BatchNorm(128),\n",
    "        MaxPool((2,2)),\n",
    "        Conv((3, 3), 128 => 256, relu, pad=(1, 1), stride=(1, 1)),\n",
    "        BatchNorm(256),\n",
    "        Conv((3, 3), 256 => 256, relu, pad=(1, 1), stride=(1, 1)),\n",
    "        BatchNorm(256),\n",
    "        Conv((3, 3), 256 => 256, relu, pad=(1, 1), stride=(1, 1)),\n",
    "        BatchNorm(256),\n",
    "        MaxPool((2,2)),\n",
    "        Conv((3, 3), 256 => 512, relu, pad=(1, 1), stride=(1, 1)),\n",
    "        BatchNorm(512),\n",
    "        Conv((3, 3), 512 => 512, relu, pad=(1, 1), stride=(1, 1)),\n",
    "        BatchNorm(512),\n",
    "        Conv((3, 3), 512 => 512, relu, pad=(1, 1), stride=(1, 1)),\n",
    "        BatchNorm(512),\n",
    "        MaxPool((2,2)),\n",
    "        Conv((3, 3), 512 => 512, relu, pad=(1, 1), stride=(1, 1)),\n",
    "        BatchNorm(512),\n",
    "        Conv((3, 3), 512 => 512, relu, pad=(1, 1), stride=(1, 1)),\n",
    "        BatchNorm(512),\n",
    "        Conv((3, 3), 512 => 512, relu, pad=(1, 1), stride=(1, 1)),\n",
    "        BatchNorm(512),\n",
    "        MaxPool((2,2)),\n",
    "        flatten,\n",
    "        Dense(512, 4096, relu),\n",
    "        Dropout(0.5),\n",
    "        Dense(4096, 4096, relu),\n",
    "        Dropout(0.5),\n",
    "        Dense(4096, 10)\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completed-automation",
   "metadata": {},
   "source": [
    "Additionally, we create a structure of default arguments that we pass to the training function. The arguments are hyper-parameters such as the batch size and learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "based-freeze",
   "metadata": {},
   "outputs": [],
   "source": [
    "@batchdef @with_kw mutable struct Args\n",
    "    batchsize::Int = 128\n",
    "    lr::Float64 = 3e-4\n",
    "    epochs::Int = 50\n",
    "    valsplit::Float64 = 0.1\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-steps",
   "metadata": {},
   "source": [
    "Finally, we implement our training function. This function takes the above defined optional input arguments and then trains the VGG16 model for a specified number of epochs. The function returns the trained network upon completion. Training is performed on a GPU if it is locally available and defaults to CPU otherwise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "comic-cinema",
   "metadata": {},
   "outputs": [],
   "source": [
    "@batchdef function train(; kws...)\n",
    "    # Initialize the hyperparameters\n",
    "    args = Args(; kws...)\n",
    "    if CUDA.has_cuda()\n",
    "        @info \"Training on GPU\"\n",
    "    else\n",
    "        @info \"Training on CPU\"\n",
    "    end\n",
    "    \n",
    "    # Load the train, validation data \n",
    "    train_data, val_data = get_processed_data(args)\n",
    "    \n",
    "    train_loader = DataLoader(train_data, batchsize=args.batchsize, shuffle=true)\n",
    "    val_loader = DataLoader(val_data, batchsize=args.batchsize)\n",
    "\n",
    "    # Move to gpu if available\n",
    "    @info(\"Constructing Model\")\n",
    "    m = vgg16() |> gpu\n",
    "\n",
    "    loss(x, y) = logitcrossentropy(m(x), y)\n",
    "\n",
    "    ## Training\n",
    "    # Defining the optimizer\n",
    "    opt = ADAM(args.lr)\n",
    "    ps = Flux.params(m)\n",
    "\n",
    "    @info(\"Training....\")\n",
    "    # Starting to train models\n",
    "    for epoch in 1:args.epochs\n",
    "        @info \"Epoch $epoch\"\n",
    "\n",
    "        for (x, y) in train_loader\n",
    "            x, y = x |> gpu, y |> gpu\n",
    "            gs = Flux.gradient(() -> loss(x,y), ps)\n",
    "            Flux.update!(opt, ps, gs)\n",
    "        end\n",
    "\n",
    "        validation_loss = 0f0\n",
    "        for (x, y) in val_loader\n",
    "            x, y = x |> gpu, y |> gpu\n",
    "            validation_loss += loss(x, y)\n",
    "        end\n",
    "        validation_loss /= length(val_loader)\n",
    "        @show validation_loss\n",
    "    end\n",
    "\n",
    "    m = m |> cpu\n",
    "    return m\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-logistics",
   "metadata": {},
   "source": [
    "Similar to the training function we define a test function, which takes the trained model as an input argument and return the testing accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "white-hospital",
   "metadata": {},
   "outputs": [],
   "source": [
    "@batchdef function test(m; kws...)\n",
    "    args = Args(kws...)\n",
    "\n",
    "    test_data = get_test_data()\n",
    "    test_loader = DataLoader(test_data, batchsize=args.batchsize)\n",
    "\n",
    "    correct, total = 0, 0\n",
    "    for (x, y) in test_loader\n",
    "        x, y = x |> gpu, y |> gpu\n",
    "        correct += sum(onecold(cpu(m(x))) .== onecold(cpu(y)))\n",
    "        total += size(y, 2)\n",
    "    end\n",
    "    test_accuracy = correct / total\n",
    "\n",
    "    # Print the final accuracy\n",
    "    @show test_accuracy\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bizarre-power",
   "metadata": {},
   "source": [
    "## Train network and hyperparameter tuning\n",
    "\n",
    "After implemeting the data loaders and network, we want to locally test our network and check that the output has the right dimensions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-rendering",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get data\n",
    "test_x, test_y = get_test_data()\n",
    "\n",
    "# Create network and test forward pass\n",
    "network = vgg16()\n",
    "ȳ = network(test_x[:,:,:,1:4])\n",
    "\n",
    "# Check output has correct dimensions\n",
    "if size(ȳ) == size(test_y[:,1:4])\n",
    "    @info \"Output dimenions match label dimensions.\"\n",
    "end\n",
    "\n",
    "# Plot images\n",
    "for j=1:4\n",
    "    subplot(1,4,j); imshow(permutedims(test_x[:,:,:,j], (2,1,3)))\n",
    "end\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-terry",
   "metadata": {},
   "source": [
    "Once we have implemented (and tested) the network and data loader, we can perform the network training. We can either:\n",
    "\n",
    "- Call the `train()` function directly, which runs the training on our local machine/laptop\n",
    "\n",
    "- Call `@batchexec train()`, which will execute the training on a remote GPU instance in the cloud\n",
    "\n",
    "To execute our training function on a remote Azure GPU instance, we use the latter command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-listing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on GPU remotely\n",
    "bctrl = @batchexec train();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-paraguay",
   "metadata": {},
   "source": [
    "We can wait for training to complete and fetch the trained model to our notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-namibia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch trained model\n",
    "m = fetch(bctrl)\n",
    "y_pred = m(test_x);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increased-button",
   "metadata": {},
   "source": [
    "In addition to running the training on a single GPU, we can even run multiple instances of our function in parallel. This is e.g. useful for hyperparameter tuning. Here, we supply a range of learning rates and then train 3 models in parallel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-consent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning in parallel\n",
    "steps = [1e-2, 1e-3, 1e-4]\n",
    "bctrl = @batchexec pmap(α -> train(; lr=α), steps);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "derived-stroke",
   "metadata": {},
   "source": [
    "Once all trainings have finished and we select the best model (e.g. by monitoring the validation loss), we can copy the best model back to our notebook (e.g. here from worker 2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-madness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch best model\n",
    "m = fetch(bctrl, 2);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-empty",
   "metadata": {},
   "source": [
    "After fetching the best trained network, we evaluate it on our testing data. Again, we can either perform testing on our local machine or remotely on our GPU VM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-carolina",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model locally\n",
    "test(m);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-building",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "The final step is to delete the pool and all consumed Azure resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-albert",
   "metadata": {},
   "outputs": [],
   "source": [
    "destroy!(bctrl);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
